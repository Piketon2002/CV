{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 9185,
     "status": "ok",
     "timestamp": 1731182943656,
     "user": {
      "displayName": "Степан Покатов",
      "userId": "03516253895235195084"
     },
     "user_tz": -180
    },
    "id": "p4GVNuQYv2VR"
   },
   "outputs": [],
   "source": [
    "# !pip install faiss-cpu --no-cache\n",
    "# !pip install opencv-python==4.8.0.76\n",
    "\n",
    "import faiss\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import euclidean\n",
    "from PIL import Image\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import zipfile\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models import resnet34\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JWPYBytmJuO-"
   },
   "source": [
    "# 0. Подготовка датасета\n",
    "\n",
    "https://www.kaggle.com/datasets/vishweshsalodkar/wild-animals\n",
    "\n",
    "В датасете есть изображения гепардов, ягуаров, леопардов, львов и тигров (примерно по 30 шт)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1736,
     "status": "ok",
     "timestamp": 1731182945388,
     "user": {
      "displayName": "Степан Покатов",
      "userId": "03516253895235195084"
     },
     "user_tz": -180
    },
    "id": "KMnVmHPNqNGm",
    "outputId": "7c11b0e3-1b4b-4b31-9b37-b382ba5a95c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/vishweshsalodkar/wild-animals\n",
      "License(s): other\n",
      "Downloading wild-animals.zip to /content\n",
      " 95% 7.00M/7.37M [00:00<00:00, 72.9MB/s]\n",
      "100% 7.37M/7.37M [00:00<00:00, 74.9MB/s]\n"
     ]
    }
   ],
   "source": [
    "! kaggle datasets download -d vishweshsalodkar/wild-animals\n",
    "\n",
    "# Распакуем архив\n",
    "with zipfile.ZipFile(\"wild-animals.zip\", 'r') as zip_ref:\n",
    "  zip_ref.extractall(\"wild-animals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1731182945388,
     "user": {
      "displayName": "Степан Покатов",
      "userId": "03516253895235195084"
     },
     "user_tz": -180
    },
    "id": "GFbIWEauqNJy",
    "outputId": "c763a187-0c66-47d8-fde9-bcd9259df9ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Объем датасета: 162\n"
     ]
    }
   ],
   "source": [
    "'''Переносим все изображения в одну папку'''\n",
    "\n",
    "source_dir = \"wild-animals/Animals\"\n",
    "target_dir = \"dataset\"\n",
    "test_dir = \"test_dataset\" # там тестовые изображения будут\n",
    "test_imgs_path = ['jaguar-1337201__340.jpg',\n",
    "                  'tiger-cub-tiger-cub-big-cat-64152.jpeg',\n",
    "                  'lion-wild-africa-african.jpg']\n",
    "\n",
    "\n",
    "if not os.path.exists(target_dir):\n",
    "  os.makedirs(target_dir)\n",
    "\n",
    "for animal_folder in os.listdir(source_dir):\n",
    "  animal_path = os.path.join(source_dir, animal_folder)\n",
    "  if os.path.isdir(animal_path):\n",
    "    for filename in os.listdir(animal_path):\n",
    "      if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        source_file = os.path.join(animal_path, filename)\n",
    "        target_file = os.path.join(target_dir, filename)\n",
    "        shutil.move(source_file, target_file)\n",
    "        # print(f\"Перемещен файл: {filename}\")\n",
    "\n",
    "\n",
    "'''Возьмем пару изображений, для которых будем искать похожие'''\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "for filename in test_imgs_path:\n",
    "  source_path = os.path.join(target_dir, filename)\n",
    "  target_path = os.path.join(test_dir, filename)\n",
    "  shutil.move(source_path, target_path)\n",
    "\n",
    "print(f\"Объем датасета: {len(os.listdir(target_dir))}\")\n",
    "# shutil.rmtree('wild-animals')\n",
    "# shutil.rmtree('dataset')\n",
    "# shutil.rmtree('test_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1731182945389,
     "user": {
      "displayName": "Степан Покатов",
      "userId": "03516253895235195084"
     },
     "user_tz": -180
    },
    "id": "1yHXEIkBfrGf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ALlB5kVMN0bo"
   },
   "source": [
    "# 1. hog и faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1731182945389,
     "user": {
      "displayName": "Степан Покатов",
      "userId": "03516253895235195084"
     },
     "user_tz": -180
    },
    "id": "yTS0KoRYxsrh"
   },
   "outputs": [],
   "source": [
    "'''инвариантный к повороту HOG дескриптор'''\n",
    "\n",
    "def HOG_init(img, mode=\"stats\"):\n",
    "    gx = cv2.Sobel(img, cv2.CV_32F, 1, 0)\n",
    "    gy = cv2.Sobel(img, cv2.CV_32F, 0, 1)\n",
    "    mag, ang = cv2.cartToPolar(gx, gy)\n",
    "\n",
    "    bin_n = 16\n",
    "    bin = np.int32(bin_n * ang / (2 * np.pi))\n",
    "\n",
    "    bin_cells = []\n",
    "    mag_cells = []\n",
    "\n",
    "    cellx = celly = 8\n",
    "\n",
    "    for i in range(0, int(img.shape[0] / celly)):\n",
    "        for j in range(0, int(img.shape[1] / cellx)):\n",
    "            temp = bin[i * celly : i * celly + celly, j * cellx : j * cellx + cellx] # берем конкретное окно\n",
    "            values, counts = np.unique(temp.ravel(), return_counts=True) # считаем кол-во значений\n",
    "\n",
    "            dict_v_c = dict(zip(values, counts))\n",
    "            dict_c_v = dict(zip(counts, values))\n",
    "\n",
    "            norm_coef = counts.max()\n",
    "\n",
    "            if mode == \"stats\":\n",
    "                temp_answer = []\n",
    "\n",
    "                for k in range(bin_n):\n",
    "                    if k in dict_v_c:\n",
    "                        temp_answer.append(dict_v_c[k] / norm_coef)\n",
    "                    else:\n",
    "                        temp_answer.append(0.0)\n",
    "\n",
    "                bin_cells.append(temp_answer)\n",
    "            else:\n",
    "                bin_cells.append(dict_c_v[norm_coef])\n",
    "\n",
    "    return np.array(bin_cells).ravel()\n",
    "\n",
    "\n",
    "# Функция вычисляет HOG дескриптор, инвариантный относительно поворота изображений за счет усреднения дескрипторов для num_rotates поворотов изображения.\n",
    "def HOG_INV(img, num_rotates=8, mode=\"stats\"):\n",
    "    '''1. Поиск центра изображения'''\n",
    "    h, w = img.shape[:2]\n",
    "    img_center = (w // 2, h // 2)\n",
    "\n",
    "    '''2. Инициализация усредненного вектора'''\n",
    "    hog_sum = np.zeros((img.shape[0] // 8 * img.shape[1] // 8 * 16,), dtype=np.float32)\n",
    "\n",
    "    '''3. Поворот изображения, вычисление HOG и добавление результата в hog_sum'''\n",
    "    for i in range(num_rotates):\n",
    "        angle = 360 / num_rotates * i\n",
    "        rotation_matrix = cv2.getRotationMatrix2D(img_center, angle, 1)\n",
    "        rotated_img = cv2.warpAffine(img, rotation_matrix, (w, h))\n",
    "        cur_hog = HOG_init(rotated_img, mode)\n",
    "        hog_sum += cur_hog\n",
    "\n",
    "    '''4. Усреднение'''\n",
    "    avg_hog = hog_sum / num_rotates\n",
    "\n",
    "    return avg_hog\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_vKQMYVszGLe"
   },
   "source": [
    "Перед извлечение признаков HOG изображений, создадим несколько вспомогательных функций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1731182945389,
     "user": {
      "displayName": "Степан Покатов",
      "userId": "03516253895235195084"
     },
     "user_tz": -180
    },
    "id": "eqWG7NLtP91b"
   },
   "outputs": [],
   "source": [
    "'''Загрузка и небольшая предобработка изображения'''\n",
    "def load_img(image_path, size=(128, 128)):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, size)\n",
    "    return img\n",
    "\n",
    "'''Извлечение HOG для всех изображений'''\n",
    "def HOG_features_extracter(dataset_path):\n",
    "    hog_features, img_path = [], []\n",
    "    for img_filename in tqdm(os.listdir(dataset_path)):\n",
    "        image_path = os.path.join(dataset_path, img_filename)\n",
    "        img = load_img(image_path)\n",
    "        hog_desc = HOG_INV(img)\n",
    "        hog_features.append(hog_desc)\n",
    "        img_path.append(image_path)\n",
    "    return np.array(hog_features, dtype=np.float32), img_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41755,
     "status": "ok",
     "timestamp": 1731182987137,
     "user": {
      "displayName": "Степан Покатов",
      "userId": "03516253895235195084"
     },
     "user_tz": -180
    },
    "id": "et-kf1ZVS_MZ",
    "outputId": "0f97285e-58bd-4d72-817a-2549e11925d9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [00:41<00:00,  3.94it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  4.90it/s]\n"
     ]
    }
   ],
   "source": [
    "'''Извлечение HOG для всех изображений'''\n",
    "hog_features, img_paths = HOG_features_extracter(target_dir)\n",
    "\n",
    "'''Извлечение HOG для тестовых изображений'''\n",
    "hog_features_test, test_img_paths = HOG_features_extracter(test_dir)\n",
    "\n",
    "'''FAISS (с L2-нормой)'''\n",
    "index = faiss.IndexFlatL2(hog_features.shape[1])\n",
    "index.add(hog_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZYMrPcrpCSpu"
   },
   "source": [
    "### Визуализируем схожие изображения\n",
    "\n",
    "Для этого 2 вспомогательные функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1731182987138,
     "user": {
      "displayName": "Степан Покатов",
      "userId": "03516253895235195084"
     },
     "user_tz": -180
    },
    "id": "jm55UjggTCE4"
   },
   "outputs": [],
   "source": [
    "'''Для вычисления L2 расстояний'''\n",
    "def calc_dists(test_embedding, similar_embeddings):\n",
    "    distances = []\n",
    "    for embedding in similar_embeddings:\n",
    "        l2_distance = euclidean(test_embedding, embedding)\n",
    "        distances.append(l2_distance)\n",
    "    return distances\n",
    "\n",
    "\n",
    "'''Визуализация исходного изображения и num_similar схожих'''\n",
    "def visualize_results(test_img_path, img_paths, I, num_similar=3):\n",
    "    # пути картинок, которые будут визуализироваться\n",
    "    similar_paths = [img_paths[idx] for idx in I[0][:num_similar]]\n",
    "    paths = [test_img_path]\n",
    "    paths.extend(similar_paths)\n",
    "    titles = ['Исходное'] + [f'Похожее № {i + 1}' for i in range(num_similar)]\n",
    "    # Визуализация\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i, path in enumerate(paths):\n",
    "        img = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        plt.subplot(1, num_similar + 1, i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(titles[i])\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1pCVWOLcRUTFsaUnc-4RHtplTU81VvzTz"
    },
    "executionInfo": {
     "elapsed": 3229,
     "status": "ok",
     "timestamp": 1731182990362,
     "user": {
      "displayName": "Степан Покатов",
      "userId": "03516253895235195084"
     },
     "user_tz": -180
    },
    "id": "7pkbsnWwi_3i",
    "outputId": "30bbdcc5-5815-4d3e-85b9-de9185882f53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NUM_SIMILAR = 3\n",
    "\n",
    "for i, test_hog_vector in enumerate(hog_features_test):\n",
    "    _, I = index.search(np.array([test_hog_vector]), NUM_SIMILAR)\n",
    "\n",
    "    similar_hogs = [hog_features[idx] for idx in I[0][:NUM_SIMILAR]]  # дескрипторы HOG для топа похожих изображений\n",
    "    distances = calc_dists(test_hog_vector, similar_hogs) # расстояния\n",
    "\n",
    "    for j, idx in enumerate(I[0][:NUM_SIMILAR]):\n",
    "        print(f\" L2 = {distances[j]:.2f} (Похожее №{j+1})\")\n",
    "    visualize_results(test_img_paths[i], img_paths, I, NUM_SIMILAR)\n",
    "    print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5wU8ktweWwsZ"
   },
   "source": [
    "# 2. Претрейны CNN на imagenet и FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1731182990362,
     "user": {
      "displayName": "Степан Покатов",
      "userId": "03516253895235195084"
     },
     "user_tz": -180
    },
    "id": "9r20jsgukzdg"
   },
   "outputs": [],
   "source": [
    "# подготовка изображений к загрузке в модель resnet\n",
    "preprocess = transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.485, 0.456, 0.406),\n",
    "                                                         (0.229, 0.224, 0.225))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1731182990362,
     "user": {
      "displayName": "Степан Покатов",
      "userId": "03516253895235195084"
     },
     "user_tz": -180
    },
    "id": "CA3-EfY0fmVJ"
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "'''Класс для того, чтобы извлекать эмбеддинги'''\n",
    "class EmbeddingExtractor:\n",
    "  def __init__(self, preprocess=preprocess, device=DEVICE):\n",
    "    self.preprocess = preprocess\n",
    "    self.model = resnet34(pretrained=True) # претрейн модели resnet34\n",
    "    self.device = device\n",
    "\n",
    "    # без \"головы\"\n",
    "    self.model = torch.nn.Sequential(*(list(self.model.children())[:-1]))\n",
    "    self.model = self.model.to(self.device)\n",
    "    self.model.eval() # градиенты не нужны\n",
    "\n",
    "  def get_feature(self, image_path):\n",
    "    tensor_img = self.preprocess(Image.open(image_path).convert('RGB')).unsqueeze(0).to(self.device)\n",
    "    with torch.no_grad():\n",
    "      embedding = self.model(tensor_img).cpu().flatten().numpy()\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1731182990363,
     "user": {
      "displayName": "Степан Покатов",
      "userId": "03516253895235195084"
     },
     "user_tz": -180
    },
    "id": "UGPAwrRKpCJO"
   },
   "outputs": [],
   "source": [
    "def get_embeddings(emb_extractor, dataset_path):\n",
    "    embeddings, img_path = [], []\n",
    "    for img_filename in tqdm(os.listdir(dataset_path)):\n",
    "        image_path = os.path.join(dataset_path, img_filename)\n",
    "        img_path.append(image_path)\n",
    "        embedding = emb_extractor.get_feature(image_path)\n",
    "        embeddings.append(embedding)\n",
    "    return np.array(embeddings), img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36238,
     "status": "ok",
     "timestamp": 1731183026594,
     "user": {
      "displayName": "Степан Покатов",
      "userId": "03516253895235195084"
     },
     "user_tz": -180
    },
    "id": "LjI7kpS6RyRK",
    "outputId": "ace64fbc-a41f-44a4-fb95-e1528d4108f5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "100%|██████████| 162/162 [00:35<00:00,  4.55it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  4.32it/s]\n"
     ]
    }
   ],
   "source": [
    "emb_extractor = EmbeddingExtractor()\n",
    "'''эмбеддинги для всех изображений'''\n",
    "embeddings, img_paths = get_embeddings(emb_extractor, target_dir)\n",
    "\n",
    "'''эмбеддинги для тестовых изображений'''\n",
    "test_embeddings, test_img_paths = get_embeddings(emb_extractor, test_dir)\n",
    "\n",
    "'''FAISS (с L2-нормой)'''\n",
    "index2 = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "index2.add(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IkgKwJV1WUPy"
   },
   "source": [
    "Визуализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1gGmU6TlphJYIEidMZC72HhaqfwFLm200"
    },
    "executionInfo": {
     "elapsed": 3064,
     "status": "ok",
     "timestamp": 1731183029650,
     "user": {
      "displayName": "Степан Покатов",
      "userId": "03516253895235195084"
     },
     "user_tz": -180
    },
    "id": "CFe6obn6nxOg",
    "outputId": "888cc6ca-300c-483d-94ad-ac3a33bd49e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NUM_SIMILAR = 3\n",
    "\n",
    "for i, test_embedding in enumerate(test_embeddings):\n",
    "    _, I = index2.search(np.array([test_embedding]), NUM_SIMILAR)\n",
    "    similar_embs = [embeddings[idx] for idx in I[0][:NUM_SIMILAR]]\n",
    "    distances = calc_dists(test_embedding, similar_embs)\n",
    "\n",
    "    for j, idx in enumerate(I[0][:NUM_SIMILAR]):\n",
    "        print(f\" L2 = {distances[j]:.2f} (Похожее №{j+1})\")\n",
    "    visualize_results(test_img_paths[i], img_paths, I, NUM_SIMILAR)\n",
    "    print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kK12z5Amp1sR"
   },
   "source": [
    "# Вывод\n",
    "\n",
    "Искать похожие на заданную картинку изображения посредством использования эмбедингов, созданных с помощью предобученной модели ResNet34, оказалось лучше, чем с помощью HOG + faiss. На примере тестовых изображений видно, что на основе HOG были случаи, когда рекомендуются не очень релавантные изображения (вместо изображения тигра например предлагается картинка с гепардом), хотя при этом значения метрики L2 были меньше, по сравнению с другими изображениями. Или например если посмотреть на первое тестовое изображение, то на основе HOG в качестве похожих изображений были предложены картинки с животными, которые тоже смотрят влево, хотя при этом сами животные разные - второй же способ уловил, что требуется искать именно льва."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1731183029650,
     "user": {
      "displayName": "Степан Покатов",
      "userId": "03516253895235195084"
     },
     "user_tz": -180
    },
    "id": "cf8UoqVkYP-I"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
